import streamlit as st
import google.generativeai as genai
import time
import os

# streamæ©Ÿèƒ½ã®è¨­å®š
def stream_res(prompt):
    try: # APIãŒæ­£ã—ãå‹•ä½œã—ã¦ã„ã‚‹ã‹ç¢ºèª
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(  # å¿œç­”ç”Ÿæˆã®è¨­å®š
                candidate_count=1,
                stop_sequences=["x"],
                max_output_tokens=200,
                temperature=1.0,
            ),
        )
    except Exception as e:
        st.error(f"An error occurred: {e}")
        return
    
    # å¿œç­”å€™è£œã‚’ãƒã‚§ãƒƒã‚¯
    if response.candidates and len(response.candidates) > 0:
        candidate = response.candidates[0]

        # å®‰å…¨æ€§ã®ç¢ºèª
        if candidate.safety_ratings and len(candidate.safety_ratings) > 0:
            # å®‰å…¨æ€§ã«å•é¡ŒãŒã‚ã‚‹å ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
            st.error("å®‰å…¨æ€§ã«é–¢ã‚ã‚‹ãŸã‚ã€ã“ã®å†…å®¹ã«ã¯å¿œç­”ã§ãã¾ã›ã‚“ã€‚")
            return
        
    # æ­£å¸¸ãªå ´åˆã¯å¿œç­”ã‚’ç”Ÿæˆ
    if candidate.text.strip():  # å¿œç­”ãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
        full_response = ""  # ãƒ«ãƒ¼ãƒ—å¤–ã§åˆæœŸåŒ–
        for word in response.text.split():
            full_response += word + " "  # å¿œç­”å…¨ä½“ã‚’è“„ç©
            yield word + " "  # éƒ¨åˆ†çš„ãªå¿œç­”ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¿”ã™
            time.sleep(0.05)
        return full_response  # å¿…è¦ãªã„ãŒæ˜ç¤ºçš„ã«å¿œç­”å…¨ä½“ã‚’è¿”ã™
    else:
        st.warning()
    """
        # æ­£å¸¸ãªå¿œç­”ã®å ´åˆã€éƒ¨åˆ†çš„ã«å¿œç­”ã‚’è¿”ã™
        if candidate.text.strip():  # å¿œç­”ãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
            full_response = ""
            for word in candidate.text.split():
                full_response += word + " "
                yield word + " "
                time.sleep(0.05)
            return full_response
        else:
            st.warning("The model did not return any valid response.")
            return "I'm sorry, I couldn't generate a response. Can you try again?"
    else:
        st.error("No valid response was returned by the model.")
        return "I'm sorry, I couldn't generate a response."

"""

# ãƒšãƒ¼ã‚¸ã®è¨­å®š(1åº¦ã ã‘å®Ÿè¡Œ)
st.set_page_config(page_title="Gemini Chatbot", page_icon=":)", layout="wide", initial_sidebar_state="auto")
st.title('Gemini Chatbot') # ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¡¨ç¤º
st.caption("ğŸš€ A streamlit chatbot powered by Gemini") # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤º

genai.configure(api_key=os.environ["GOOGLE_API_KEY"]) # APIã‚­ãƒ¼ã‚’è¨­å®š
# TODO: ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠå¤‰æ›´äºˆå®š
model = genai.GenerativeModel('gemini-1.5-flash') # ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ (gemini-1.5-flash)

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Get started by typing something!"}
        ]

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ã‚’è¡¨ç¤º
if prompt := st.chat_input("Type something..."):
    # ãƒ¦ãƒ¼ã‚¶ãŒå…¥åŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å±¥æ­´ã«è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": prompt})
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
    with st.chat_message("user"):
        st.markdown(prompt)

    # # å¿œç­”ã‚’ç”Ÿæˆ
    # response = model.generate_content(
    #     prompt,
    #     generation_config=genai.types.GenerationConfig( # å¿œç­”ç”Ÿæˆã®è¨­å®š
    #         candidate_count=1,
    #         stop_sequences=["x"],
    #         max_output_tokens=200,
    #         temperature=1.0,
    #     ),
    # ) 
    # å¿œç­”ã‚’è¡¨ç¤º
# AIã®å¿œç­”ã‚’ç”Ÿæˆã—ã€æµã‚Œã‚‹ã‚ˆã†ã«è¡¨ç¤º
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã€éƒ¨åˆ†çš„ã«å¿œç­”ã‚’è¡¨ç¤º
        for word in stream_res(prompt):
            full_response += word  # å…¨ä½“ã®å¿œç­”ã‚’è“„ç©
            message_placeholder.markdown(full_response)  # éƒ¨åˆ†çš„ãªå¿œç­”ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤º

    
    # å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
    st.session_state.messages.append({"role": "assistant", "content": full_response})

